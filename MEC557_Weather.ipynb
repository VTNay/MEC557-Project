{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VTNay/MEC557-Project/blob/Ma/MEC557_Weather.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1ae401f",
      "metadata": {
        "id": "f1ae401f"
      },
      "source": [
        "# Projects\n",
        "\n",
        "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.in2p3.fr%2Fenergy4climate%2Fpublic%2Feducation%2Fmachine_learning_for_climate_and_energy/master?filepath=book%2Fnotebooks%2Fprojects.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfvEaXMCKKvc",
        "outputId": "1e863bac-2669-4538-b140-1779a5f92eb7"
      },
      "id": "EfvEaXMCKKvc",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03d41164",
      "metadata": {
        "id": "03d41164"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    <b>Schedule</b>\n",
        "    \n",
        "- Ask your supervisors for the data if not already provided (it is not included in this repository).\n",
        "- Quick presentation.\n",
        "- Final project presentation.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01b8a8b3",
      "metadata": {
        "id": "01b8a8b3"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    <b>One problematic, One dataset, One (or more) method(s)</b>\n",
        "    \n",
        "- Quality of the dataset is key.\n",
        "- Results on a clean notebook.\n",
        "- Explain which method(s) you used and why.\n",
        "- If a method fails, explain why.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b309f16e",
      "metadata": {
        "id": "b309f16e"
      },
      "source": [
        "## Project: Weather station"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "912d896e",
      "metadata": {
        "id": "912d896e"
      },
      "source": [
        "<img alt=\"weather\" src=\"https://github.com/VTNay/MEC557-Project/blob/main/images/map.png?raw=1\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2372e364",
      "metadata": {
        "id": "2372e364"
      },
      "source": [
        "- Suppose there are 5 weather stations that monitor the weather: Paris, Brest, London, Marseille and Berlin.\n",
        "- The weather station in Paris breaks down\n",
        "- Can we use the other stations to infer the weather in Paris"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66ae5a0d",
      "metadata": {
        "id": "66ae5a0d"
      },
      "source": [
        "### Data set\n",
        "\n",
        "<img alt=\"weather\" src=\"https://github.com/VTNay/MEC557-Project/blob/main/images/annual_temperature.png?raw=1\" width=400>\n",
        "\n",
        "- Surface variables: skt, u10, v10, t2m, d2m, tcc, sp, tp, ssrd, blh\n",
        "- Temporal resolution: hourly\n",
        "- Spatial resolution: N/A"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73ad9743",
      "metadata": {
        "id": "73ad9743"
      },
      "source": [
        "### First steps\n",
        "\n",
        "- Look at the correlations between variables.\n",
        "- What variable do I want to predict\n",
        "- What time scale am interested in?\n",
        "- Start with the easy predictions and move on to harder ones\n",
        "- Are there events that are more predictable than others?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "from functools import reduce\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Define file paths for weather data of different cities\n",
        "weather_paths = {\n",
        "    'Paris': Path('/content/drive/My Drive/PHY557_Project/weather/paris'),\n",
        "    'Brest': Path('/content/drive/My Drive/PHY557_Project/weather/brest'),\n",
        "    'London': Path('/content/drive/My Drive/PHY557_Project/weather/london'),\n",
        "    'Marseille': Path('/content/drive/My Drive/PHY557_Project/weather/marseille'),\n",
        "    'Berlin': Path('/content/drive/My Drive/PHY557_Project/weather/berlin')\n",
        "}\n",
        "\n",
        "# Define the names of the files for each weather parameter\n",
        "file_names = {\n",
        "    't2m': 't2m.nc', 'blh': 'blh.nc', 'd2m': 'd2m.nc', 'skt': 'skt.nc',\n",
        "    'sp': 'sp.nc', 'ssrd': 'ssrd.nc', 'tcc': 'tcc.nc', 'tp': 'tp.nc',\n",
        "    'u10': 'u10.nc', 'v10': 'v10.nc'\n",
        "}\n",
        "\n",
        "# Initialize a dictionary to store weather data for each city\n",
        "weather_data = {city: {} for city in weather_paths}\n",
        "\n",
        "# Load and preprocess the data for each city\n",
        "for city, path in weather_paths.items():\n",
        "    for param, file_name in file_names.items():\n",
        "        # Load the dataset\n",
        "        dataset = xr.open_dataset(Path(path, file_name)).to_dataframe()\n",
        "        # Drop unnecessary levels based on the parameter\n",
        "        if param in ['d2m', 'blh']:\n",
        "            dataset = dataset.droplevel([1, 2])\n",
        "        else:\n",
        "            dataset = dataset.droplevel([0, 1])\n",
        "        # Store the processed data\n",
        "        weather_data[city][param] = dataset\n",
        "    # Merge data from different parameters into a single dataframe\n",
        "    weather_data[city] = reduce(lambda left, right: pd.merge(\n",
        "        left, right, left_index=True, right_index=True, how='outer'),\n",
        "        weather_data[city].values())\n",
        "\n",
        "# Function to rename columns with city prefix\n",
        "def rename_columns(df, prefix):\n",
        "    \"\"\"Rename columns with a city prefix.\"\"\"\n",
        "    return df.rename(columns={col: f\"{prefix}_{col}\" for col in df.columns})\n",
        "\n",
        "# Rename columns and concatenate data from all cities\n",
        "combined_data = pd.concat([rename_columns(weather_data[city], city) for city in weather_data], axis=1)\n",
        "\n",
        "# Data cleaning\n",
        "# Drop rows with missing values\n",
        "combined_data = combined_data.dropna()\n",
        "\n",
        "# Split the combined data into features (X) and target (y)\n",
        "X_raw = combined_data.iloc[:,10:]  # Features from all cities except Paris\n",
        "y = combined_data['Paris_t2m']  # Target: temperature in Paris\n",
        "\n",
        "# Normalize features and target\n",
        "X_normalized = (X_raw - X_raw.mean()) / X_raw.std()\n",
        "y_normalized = (y - y.mean()) / y.std()\n",
        "\n",
        "# Calculate the number of years in the dataset\n",
        "n_years = y_normalized.index.year.max() - y_normalized.index.year.min() + 1\n",
        "\n",
        "print(X_normalized.columns)\n",
        "print('Number of years: {}'.format(n_years))"
      ],
      "metadata": {
        "id": "_AFDHEOp8-F1"
      },
      "id": "_AFDHEOp8-F1",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PCA**"
      ],
      "metadata": {
        "id": "E8xgsWcB_n48"
      },
      "id": "E8xgsWcB_n48"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso is a linear model that uses this cost function:\n",
        "\n",
        "$$\n",
        "\\frac{1}{2N_{\\text{training}}} \\sum_{i=1}^{N_{\\text{training}}} \\left( y^{(i)}_{\\text{real}} - y^{(i)}_{\\text{pred}} \\right)^2 + \\alpha \\sum_{j=1}^{n} |a_j|\n",
        "$$\n",
        "\n",
        "$a_j$ is the coefficient of the j-th feature. The final term is called $l_1$ penalty and $\\alpha$ is a hyperparameter that tunes the intensity of this penalty term. The higher the coefficient of a feature, the higher the value of the cost function. So, the idea of Lasso regression is to optimize the cost function reducing the absolute values of the coefficients.\n"
      ],
      "metadata": {
        "id": "1Fa2OtwzAsbH"
      },
      "id": "1Fa2OtwzAsbH"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.datasets import make_regression\n",
        "# Set number of splits for cross-validation - two years for each fold\n",
        "n_splits =  5 # We have 40 years in total\n",
        "\n",
        "# Initialize LassoCV, which will perform cross-validation\n",
        "lasso = LassoCV(cv=n_splits, random_state=0, max_iter=10000)\n",
        "\n",
        "# Fit the Lasso model to the data\n",
        "lasso.fit(X_raw, y)\n",
        "# Number of features remained\n",
        "n_features = 20\n",
        "# n_features features having the highest absolute value of coefficient can be considered as more important or keeped\n",
        "indices_top = np.argsort(np.abs(lasso.coef_))[-n_features:]\n",
        "selected_features = [X_raw.columns[i] for i in indices_top]\n",
        "\n",
        "# To reduce the feature set\n",
        "X = X_raw[selected_features]"
      ],
      "metadata": {
        "id": "BTs-B6vc_xfZ"
      },
      "id": "BTs-B6vc_xfZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Core Fucntion ##"
      ],
      "metadata": {
        "id": "Bg_10e6ephP5"
      },
      "id": "Bg_10e6ephP5"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import numpy as np\n",
        "\n",
        "def poly_ridge(degree, X, y, alpha_values, n_splits_cv, test_size):\n",
        "    \"\"\"\n",
        "    Performs polynomial regression with Ridge regularization.\n",
        "\n",
        "    Args:\n",
        "    degree (int): The degree of the polynomial features.\n",
        "    X (DataFrame): The features dataset.\n",
        "    y (Series): The target dataset.\n",
        "    alpha_values (array): Array of alpha values for regularization.\n",
        "    n_splits_cv (int): Number of splits for cross-validation.\n",
        "    test_size (float): The proportion of the dataset to include in the test split.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary containing model performance metrics and optimal parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_cv, X_test, y_cv, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
        "\n",
        "    # Initialize arrays for storing scores and coefficients\n",
        "    r2_validation = np.empty(len(alpha_values))\n",
        "\n",
        "    # Loop over different values of alpha (regularization strength)\n",
        "    for i, alpha in enumerate(alpha_values):\n",
        "        # Transform data to include polynomial features, include_bias=False because Ridge has the intercept by default\n",
        "        polynomial_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
        "        # Create a pipeline with polynomial features and ridge regression\n",
        "        model = make_pipeline(polynomial_features, Ridge(alpha=alpha))\n",
        "\n",
        "        # Calculate the mean R^2 score from k-fold cross-validation\n",
        "        r2_validation[i] = cross_val_score(model, X_cv, y_cv, cv=n_splits_cv).mean()\n",
        "\n",
        "    # Find the index of the best alpha value\n",
        "    i_best = np.argmax(r2_validation)\n",
        "    alpha_best = alpha_values[i_best]\n",
        "\n",
        "    # Train the model with the best alpha value on the full CV dataset\n",
        "    best_model = make_pipeline(PolynomialFeatures(degree=degree, include_bias=False), Ridge(alpha=alpha_best))\n",
        "    best_model.fit(X_cv, y_cv)\n",
        "\n",
        "    # Calculate R^2 score on the test dataset\n",
        "    r2_test = best_model.score(X_test, y_test)\n",
        "\n",
        "    # Return a dictionary containing the results\n",
        "    return {\n",
        "        'r2_validation': r2_validation,\n",
        "        'i_best': i_best,\n",
        "        'alpha_best': alpha_best,\n",
        "        'r2_test': r2_test\n",
        "    }"
      ],
      "metadata": {
        "id": "3I5bkqc3BNJW"
      },
      "id": "3I5bkqc3BNJW",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage\n",
        "# results = poly_ridge(degree=3, X=X_normalized, y=y_normalized, alpha_values=np.logspace(-4, 4, 10), n_splits_cv=5, test_size=0.25)\n",
        "# print(results)"
      ],
      "metadata": {
        "id": "Lrh-F4MRBQZZ"
      },
      "id": "Lrh-F4MRBQZZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Degree 1\n",
        "results_1 = poly_ridge(degree=1, X=X_normalized, y=y_normalized, alpha_values=np.logspace(-4, 4, 10), n_splits_cv=5, test_size=0.25)\n",
        "print(results_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM1GO0iWvLN-",
        "outputId": "34a30daf-8e4a-40be-c106-00736d02ab34"
      },
      "id": "fM1GO0iWvLN-",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'r2_validation': array([0.91979407, 0.91979407, 0.91979407, 0.91979407, 0.91979407,\n",
            "       0.91979407, 0.91979388, 0.91978109, 0.91932145, 0.91427955]), 'i_best': 4, 'alpha_best': 0.3593813663804626, 'r2_test': 0.920514343333126}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Degree 2\n",
        "results_2 = poly_ridge(degree=2, X=X_normalized, y=y_normalized, alpha_values=np.logspace(-4, 4, 10), n_splits_cv=5, test_size=0.25)\n",
        "print(results_2)"
      ],
      "metadata": {
        "id": "dMSyPMaE05y-",
        "outputId": "5d37278f-b096-46f1-a377-86fe82c893e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dMSyPMaE05y-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.83709e-08): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.51772e-08): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.7265e-08): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.73477e-08): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.83709e-08): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.51772e-08): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.7265e-08): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.73477e-08): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.83912e-08): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.51868e-08): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Degree 3\n",
        "results_3 = poly_ridge(degree=3, X=X_normalized, y=y_normalized, alpha_values=np.logspace(-4, 4, 10), n_splits_cv=5, test_size=0.25)\n",
        "print(results_3)"
      ],
      "metadata": {
        "id": "nFZ7m5Qa1Evo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195ca7ce-532f-4a43-f58b-e65328a85039"
      },
      "id": "nFZ7m5Qa1Evo",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'r2_validation': array([0.91979407, 0.91979407, 0.91979407, 0.91979407, 0.91979407,\n",
            "       0.91979407, 0.91979388, 0.91978109, 0.91932145, 0.91427955]), 'i_best': 4, 'alpha_best': 0.3593813663804626, 'r2_test': 0.920514343333126}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad79471d",
      "metadata": {
        "id": "ad79471d"
      },
      "source": [
        "***\n",
        "## Credit\n",
        "\n",
        "[//]: # \"This notebook is part of [E4C Interdisciplinary Center - Education](https://gitlab.in2p3.fr/energy4climate/public/education).\"\n",
        "Contributors include Bruno Deremble and Alexis Tantet.\n",
        "Several slides and images are taken from the very good [Scikit-learn course](https://inria.github.io/scikit-learn-mooc/).\n",
        "\n",
        "<br>\n",
        "\n",
        "<div style=\"display: flex; height: 70px\">\n",
        "    \n",
        "<img alt=\"Logo LMD\" src=\"https://github.com/VTNay/MEC557-Project/blob/main/images/logos/logo_lmd.jpg?raw=1\" style=\"display: inline-block\"/>\n",
        "\n",
        "<img alt=\"Logo IPSL\" src=\"https://github.com/VTNay/MEC557-Project/blob/main/images/logos/logo_ipsl.png?raw=1\" style=\"display: inline-block\"/>\n",
        "\n",
        "<img alt=\"Logo E4C\" src=\"https://github.com/VTNay/MEC557-Project/blob/main/images/logos/logo_e4c_final.png?raw=1\" style=\"display: inline-block\"/>\n",
        "\n",
        "<img alt=\"Logo EP\" src=\"https://github.com/VTNay/MEC557-Project/blob/main/images/logos/logo_ep.png?raw=1\" style=\"display: inline-block\"/>\n",
        "\n",
        "<img alt=\"Logo SU\" src=\"https://github.com/VTNay/MEC557-Project/blob/main/images/logos/logo_su.png?raw=1\" style=\"display: inline-block\"/>\n",
        "\n",
        "<img alt=\"Logo ENS\" src=\"https://github.com/VTNay/MEC557-Project/blob/main/images/logos/logo_ens.jpg?raw=1\" style=\"display: inline-block\"/>\n",
        "\n",
        "<img alt=\"Logo CNRS\" src=\"https://github.com/VTNay/MEC557-Project/blob/main/images/logos/logo_cnrs.png?raw=1\" style=\"display: inline-block\"/>\n",
        "    \n",
        "</div>\n",
        "\n",
        "<hr>\n",
        "\n",
        "<div style=\"display: flex\">\n",
        "    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0; margin-right: 10px\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a>\n",
        "    <br>This work is licensed under a &nbsp; <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": true,
      "autocomplete": false,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}